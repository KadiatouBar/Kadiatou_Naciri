{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate, RandomSharpen\n",
    "from mltu.annotations.images import CVImage\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
    "from mltu.tensorflow.metrics import CWERMetric\n",
    "\n",
    "import mltu\n",
    "import os\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime\n",
    "\n",
    "from mltu.configs import BaseModelConfigs\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from mltu.tensorflow.model_utils import residual_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration améliorée pour une gestion des paramètres plus claire\n",
    "class ModelConfigs(BaseModelConfigs):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = os.path.join(\"kaggle/working/Models/03_handwriting_recognition\", \"improved_model\")\n",
    "        self.vocab = \"\"\n",
    "        self.height = 32\n",
    "        self.width = 128\n",
    "        self.max_text_length = 0\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 0.0005\n",
    "        self.train_epochs = 1  # Augmenté pour un meilleur apprentissage\n",
    "        self.train_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Couche de normalisation personnalisée\n",
    "class NormalizeLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.image.per_image_standardization(inputs)\n",
    "\n",
    "# Modèle amélioré\n",
    "def train_model(input_dim, output_dim, activation=\"relu\", dropout=0.3):\n",
    "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
    "    normalized_inputs = NormalizeLayer()(inputs)\n",
    "\n",
    "    x = residual_block(normalized_inputs, 16, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "    for filters, strides in [(32, 2), (64, 2)]:\n",
    "        x = residual_block(x, filters, activation=activation, skip_conv=True, strides=strides, dropout=dropout)\n",
    "        x = residual_block(x, filters, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    squeezed = layers.Reshape((x.shape[-3] * x.shape[-2], x.shape[-1]))(x)\n",
    "    blstm = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(squeezed)  # Augmenté à 256\n",
    "    blstm = layers.Dropout(dropout)(blstm)\n",
    "\n",
    "    output = layers.Dense(output_dim + 1, activation=\"softmax\", name=\"output\")(blstm)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Téléchargement et extraction avec gestion des erreurs\n",
    "def download_and_unzip(url, extract_to=\"Datasets\"):\n",
    "    try:\n",
    "        http_response = urlopen(url)\n",
    "        zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "        zipfile.extractall(path=extract_to)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement : {e}\")\n",
    "        raise\n",
    "\n",
    "# Préparation des données\n",
    "dataset_path = os.path.join(\"Datasets\", \"IAM_Words\")\n",
    "\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    download_and_unzip(\"https://git.io/J0fjL\", extract_to=\"Datasets\")\n",
    "    file = tarfile.open(os.path.join(dataset_path, \"words.tgz\"))\n",
    "    file.extractall(os.path.join(dataset_path, \"words\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset, vocab, max_len = [], set(), 0\n",
    "words = open(os.path.join(dataset_path, \"words.txt\"), \"r\").readlines()\n",
    "for line in tqdm(words):\n",
    "    if line.startswith(\"#\") or \"err\" in line:\n",
    "        continue\n",
    "    line_split = line.split(\" \")\n",
    "    folder1, folder2, file_name = line_split[0][:3], \"-\".join(line_split[0].split(\"-\")[:2]), f\"{line_split[0]}.png\"\n",
    "    label = line_split[-1].rstrip(\"\\n\")\n",
    "\n",
    "    rel_path = os.path.join(dataset_path, \"words\", folder1, folder2, file_name)\n",
    "    if not os.path.exists(rel_path):\n",
    "        print(f\"Fichier non trouvé : {rel_path}\")\n",
    "        continue\n",
    "\n",
    "    dataset.append([rel_path, label])\n",
    "    vocab.update(list(label))\n",
    "    max_len = max(max_len, len(label))\n",
    "\n",
    "# Mise à jour de la configuration\n",
    "configs = ModelConfigs()\n",
    "configs.vocab = \"\".join(vocab)\n",
    "configs.max_text_length = max_len\n",
    "configs.save()\n",
    "\n",
    "# Chargement des données avec transformations\n",
    "data_provider = DataProvider(\n",
    "    dataset=dataset,\n",
    "    skip_validation=True,\n",
    "    batch_size=configs.batch_size,\n",
    "    data_preprocessors=[ImageReader(CVImage)],\n",
    "    transformers=[\n",
    "        ImageResizer(configs.width, configs.height, keep_aspect_ratio=False),\n",
    "        LabelIndexer(configs.vocab),\n",
    "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab)),\n",
    "    ],\n",
    ")\n",
    "train_data_provider, val_data_provider = data_provider.split(split=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ajout d'augmentations de données\n",
    "train_data_provider.augmentors = [\n",
    "    RandomBrightness(),\n",
    "    RandomErodeDilate(),\n",
    "    RandomSharpen(),\n",
    "    RandomRotate(angle=15),  # Rotation augmentée\n",
    "]\n",
    "\n",
    "# Construction et compilation du modèle\n",
    "model = train_model(\n",
    "    input_dim=(configs.height, configs.width, 3),\n",
    "    output_dim=len(configs.vocab),\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate),\n",
    "    loss=CTCloss(),\n",
    "    metrics=[CWERMetric(padding_token=len(configs.vocab))],\n",
    ")\n",
    "model.summary(line_length=120)\n",
    "\n",
    "# Callbacks optimisés\n",
    "earlystopper = EarlyStopping(monitor=\"val_CER\", mode=\"min\", patience=10, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath=f\"{configs.model_path}/model.keras\", monitor=\"val_CER\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "trainLogger = TrainLogger(configs.model_path)\n",
    "tb_callback = TensorBoard(log_dir=f\"{configs.model_path}/logs\", update_freq=1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.5, patience=5, verbose=1, mode=\"min\")\n",
    "model2onnx = Model2onnx(f\"{configs.model_path}/model.keras\")\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(\n",
    "    train_data_provider,\n",
    "    validation_data=val_data_provider,\n",
    "    epochs=configs.train_epochs,\n",
    "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
    ")\n",
    "\n",
    "# Sauvegarde des ensembles d'entraînement et de validation\n",
    "train_data_provider.to_csv(os.path.join(configs.model_path, \"train.csv\"))\n",
    "val_data_provider.to_csv(os.path.join(configs.model_path, \"val.csv\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
